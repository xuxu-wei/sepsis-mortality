{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import pickle\n",
    "# 检测运行环境\n",
    "def in_notebook():\n",
    "    return 'IPKernelApp' in getattr(globals().get('get_ipython', lambda: None)(), 'config', {})\n",
    "\n",
    "if in_notebook():\n",
    "    from IPython.display import clear_output, display\n",
    "    notebook_dir = os.getcwd()\n",
    "    src_path = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "    RUN_MODE = 'tuning' # reload: 重现study; tuning 搜索超参数\n",
    "    N_TRIAL = 3\n",
    "    OUTCOME_IX = 1\n",
    "else:\n",
    "    src_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    parser.add_argument('-n',metavar= 50, type=int, default=50,help='''optuna优化尝试次数''')\n",
    "    parser.add_argument('-outcome_ix',metavar= 0, type=int, default=0,help='''选择预测结局, 为 `get_ite_features()`返回的预设 outcomes 列表的索引''')\n",
    "    sys_args = parser.parse_args()\n",
    "    N_TRIAL = sys_args.n\n",
    "    OUTCOME_IX = sys_args.outcome_ix\n",
    "    RUN_MODE = 'tuning' # 脚本模式只做tuing!\n",
    "\n",
    "sys.path.append(src_path) if src_path not in sys.path else None\n",
    "\n",
    "from src.utils import *\n",
    "from src.model_utils import *\n",
    "from src.setup import *\n",
    "from ite_setup import *\n",
    "from ganite_mod import Ganite, GaniteRegressor\n",
    "from ganite_mod.utils.metrics import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'current device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA}/imputed/EXIT_SEP_clean_imputed.tsv.gz', sep='\\t', index_col='ID')\n",
    "features, _, _, treatment, outcomes = get_ite_features()\n",
    "current_outcome = outcomes[OUTCOME_IX] # 设置预测目标\n",
    "\n",
    "df_train = df.sample(frac=0.7, random_state=19960816)\n",
    "df_test = df[~df.index.isin(df_train.index)].copy()\n",
    "X, W, y = load_data(df, outcome_ix=OUTCOME_IX)\n",
    "\n",
    "X = np.array(X)\n",
    "W = np.array(W)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE=='tuning':\n",
    "    # 建立文件输出路径\n",
    "    current_time = datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "    optuna_result_path = f'{MODELS}/GANITE_optuna-{current_outcome}-{formatted_time}-{sys.platform}/'\n",
    "    # optuna_fig_path = f'{FIGS}/GANITE_optuna-{current_outcome}-{formatted_time}-{sys.platform}/'\n",
    "    optuna_fig_path = optuna_result_path # 统一输出路径\n",
    "\n",
    "    os.makedirs(optuna_fig_path, exist_ok=True)\n",
    "    os.makedirs(optuna_result_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    def objective(trial):\n",
    "        # 定义需要调优的超参数范围\n",
    "        dim_hidden = trial.suggest_int(\"dim_hidden\", 70, 400, step=10)\n",
    "        alpha = trial.suggest_float(\"alpha\", 0.0, 3.0, step=0.05)\n",
    "        beta = trial.suggest_float(\"beta\", 0.0, 3.0, step=0.05)\n",
    "        depth = trial.suggest_int(\"depth\", 1, 5, step=1)\n",
    "        minibatch_size = trial.suggest_categorical(\"minibatch_size\", [200, 300, 400])\n",
    "        num_iterations = trial.suggest_int(\"num_iterations\", 1000, 2500, step=500)\n",
    "        num_discr_iterations = trial.suggest_categorical(\"num_discr_iterations\", [1, 2, 3])\n",
    "\n",
    "        # 初始化模型\n",
    "        model = GaniteRegressor(\n",
    "            dim_in=X.shape[1],\n",
    "            binary_y=True,\n",
    "            dim_hidden=dim_hidden,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            depth=depth,\n",
    "            minibatch_size=minibatch_size,\n",
    "            num_iterations=num_iterations,\n",
    "            num_discr_iterations=num_discr_iterations,\n",
    "        )\n",
    "\n",
    "        # 实现交叉验证\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=19960816)\n",
    "        aucs = []\n",
    "        scores = []\n",
    "        ate_losses_ob = []\n",
    "        ate_losses = []\n",
    "\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            # 划分训练集和验证集\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            T_train, T_val = W[train_index], W[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            \n",
    "            # 训练模型\n",
    "            model.fit((X_train, T_train), y_train)\n",
    "            \n",
    "            # 验证模型并记录分数\n",
    "            score_temp = model.score((X_val, T_val), y_val)  # 默认负均方误差\n",
    "            neg_ate_l1_loss_ob_temp = model.ate_l1_loss((X_val, T_val), y_val, eval_strategy='observed_only')  # 负 ATE 误差, 仅比较观测组间误差\n",
    "            neg_ate_l1_loss_temp = model.ate_l1_loss((X_val, T_val), y_val, eval_strategy='mean_ITE')  # 负 ATE 误差\n",
    "            auc = model.roc_auc((X_val, T_val), y_val, average='weighted')\n",
    "\n",
    "            aucs.append(auc)\n",
    "            scores.append(score_temp)\n",
    "            ate_losses_ob.append(neg_ate_l1_loss_ob_temp)\n",
    "            ate_losses.append(neg_ate_l1_loss_temp)\n",
    "\n",
    "        # 返回平均交叉验证分数（负均方误差）\n",
    "        return np.mean(aucs), np.mean(scores), np.mean(ate_losses_ob), np.mean(ate_losses)\n",
    "\n",
    "    # 日志功能：设置 Optuna 的日志级别\n",
    "    # optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "    # 实时打印当前最佳结果\n",
    "    def trial_callback(study, trial):\n",
    "        if in_notebook():\n",
    "            clear_output(wait=True)  # 清除之前的输出\n",
    "            df_trials = study.trials_dataframe()  # 获取当前的试验数据\n",
    "            display(df_trials)  # 动态显示最新的 dataframe\n",
    "\n",
    "            # 多目标优化时 打印 Pareto 前沿解\n",
    "            if len(study.directions) > 1:\n",
    "                pareto_front = study.best_trials\n",
    "                print(f\"Number of Pareto optimal solutions: {len(pareto_front)}\")\n",
    "                for i, trial in enumerate(pareto_front):\n",
    "                    print(f\"Pareto solution {i}: Values {trial.values}, Params {trial.params}\")\n",
    "            else:\n",
    "                print(f\"Current best value: {study.best_value}\")\n",
    "                print(f\"Current best parameters: {study.best_params}\")\n",
    "                print(f\"Current best trial: {study.best_trials}\")\n",
    "        else:\n",
    "            # 多目标优化时 打印首选 Pareto 前沿解的结果和参数\n",
    "            if len(study.directions) > 1:\n",
    "                pareto_front = study.best_trials\n",
    "                best_trial = pareto_front[0]\n",
    "                print(f\"Trial {trial.number}/{N_TRIAL} finished with value: {trial.values} and parameters: {trial.params} | crrent best value: {best_trial.values} and parameters: {best_trial.params} | Number of Pareto optimal solutions: {len(pareto_front)}\")\n",
    "            else:\n",
    "                print(f\"Trial {trial.number}/{N_TRIAL} finished with value: {trial.value} and parameters: {trial.params} | crrent best value: {study.best_value} and parameters: {study.best_params}\")\n",
    "\n",
    "\n",
    "    # 使用 Optuna 优化\n",
    "    study = optuna.create_study(directions=[\"maximize\", \"maximize\", \"maximize\", \"maximize\",])  # 或 \"minimize\"，取决于评分标准\n",
    "    study.optimize(objective, n_trials=N_TRIAL, callbacks=[trial_callback])\n",
    "\n",
    "    # 保存实验结果\n",
    "    with open(f\"{optuna_result_path}/optuna_study.pkl\", \"wb\") as f:\n",
    "        print('调参结束，正在保存optuna调参试验结果')\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "    # 获取 Pareto 前沿解\n",
    "    pareto_front = study.best_trials\n",
    "    print(\"Pareto Front Solutions:\")\n",
    "    for trial in pareto_front:\n",
    "        print(f\"Trial {trial.number}: Values {trial.values}, Params {trial.params}\")\n",
    "\n",
    "    # 保存 Pareto 解到文件\n",
    "    pareto_data = [\n",
    "        {\"trial_number\": trial.number, \"values\": trial.values, \"params\": trial.params}\n",
    "        for trial in pareto_front\n",
    "    ]\n",
    "    with open(f\"{optuna_result_path}/pareto_solutions.json\", \"w\") as f:\n",
    "        json.dump(pareto_data, f)\n",
    "\n",
    "\n",
    "    # 保存完整调参历史为 xlsx 文件\n",
    "    df_trials = study.trials_dataframe()\n",
    "    df_trials.to_excel(f\"{optuna_result_path}/tuning_history.xlsx\", index=False)\n",
    "\n",
    "    # 使用一个 Pareto 最优解重新初始化模型\n",
    "    best_trial = pareto_front[0] # 选择第一个 Pareto 解\n",
    "    best_params = best_trial.params\n",
    "    # 使用最佳参数重新初始化模型\n",
    "    best_model = GaniteRegressor(\n",
    "        dim_in=X.shape[1],\n",
    "        binary_y=True,\n",
    "        dim_hidden=best_params[\"dim_hidden\"],\n",
    "        alpha=best_params[\"alpha\"],\n",
    "        beta=best_params[\"beta\"],\n",
    "        depth=best_params[\"depth\"],\n",
    "        num_iterations=best_params[\"num_iterations\"],\n",
    "        num_discr_iterations=best_params[\"num_discr_iterations\"],\n",
    "    )\n",
    "\n",
    "    # 训练最佳模型\n",
    "    print('使用最佳参数在全集上模型')\n",
    "    best_model.fit((X, W), y)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    print('训练完成，保存模型参数')\n",
    "    torch.save(best_model.state_dict(), f\"{optuna_result_path}/GANITE_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE=='reload':\n",
    "    optuna_result_path = f'{MODELS}/GANITE_optuna-28d_mortality-2024-11-28_23-14-linux/'\n",
    "    with open(f\"{optuna_result_path}/optuna_study.pkl\", \"rb\") as f:\n",
    "        print('正在加载指定optuna调参试验结果')\n",
    "        study = pickle.load(f)\n",
    "\n",
    "from optuna.visualization import (\n",
    "    plot_parallel_coordinate,\n",
    "    plot_param_importances,\n",
    "    plot_contour,\n",
    "    plot_slice,\n",
    "    plot_optimization_history,\n",
    "    plot_pareto_front,\n",
    ")\n",
    "\n",
    "# 绘制不同的图表\n",
    "target_args_1 = dict(target = lambda t: -t.values[0], target_name=\"AUC\")\n",
    "target_args_2 = dict(target = lambda t: -t.values[1], target_name=\"Berier Score\")\n",
    "target_args_3 = dict(target = lambda t: -t.values[2], target_name=\"ATE_observed L1-loss\")\n",
    "target_args_4 = dict(target = lambda t: -t.values[3], target_name=\"ATE L1-loss\")\n",
    "targets_args = dict(targets = lambda t: [t.values[0], -t.values[3]], target_names=[\"AUC\", \"ΔATE\"])\n",
    "\n",
    "# 并行坐标图\n",
    "parallel_coordinate_fig = plot_parallel_coordinate(study, **target_args_1)\n",
    "parallel_coordinate_fig.update_layout(width=800, height=600)\n",
    "parallel_coordinate_fig.show() if in_notebook() else None\n",
    "parallel_coordinate_fig.write_image(f\"{optuna_fig_path}/parallel_coordinate_fig.svg\", format='svg', scale=2, width=700, height=500) if not in_notebook() else None\n",
    "\n",
    "# 参数重要性图\n",
    "param_importance_fig = plot_param_importances(study, **target_args_1)\n",
    "param_importance_fig.update_layout(width=800, height=600)\n",
    "param_importance_fig.show() if in_notebook() else None\n",
    "param_importance_fig.write_image(f\"{optuna_fig_path}/param_importance_fig.svg\", format='svg', scale=2, width=700, height=500) if not in_notebook() else None\n",
    "\n",
    "# 平行曲面图\n",
    "contour_fig = plot_contour(study, **target_args_1)\n",
    "contour_fig.update_layout(width=1200, height=1200)\n",
    "contour_fig.show() if in_notebook() else None\n",
    "contour_fig.write_image(f\"{optuna_fig_path}/contour_fig.svg\", format='svg', scale=2, width=1200, height=1200) if not in_notebook() else None\n",
    "\n",
    "# 超参数分布图\n",
    "slice_fig = plot_slice(study, **target_args_1)\n",
    "slice_fig.show() if in_notebook() else None\n",
    "slice_fig.write_image(f\"{optuna_fig_path}/slice_fig.svg\", format='svg', scale=2, width=2500, height=400) if not in_notebook() else None\n",
    "\n",
    "# 优化历史图\n",
    "optimization_history_fig = plot_optimization_history(study, **target_args_1)\n",
    "optimization_history_fig.update_layout(width=700, height=500)\n",
    "optimization_history_fig.show() if in_notebook() else None\n",
    "optimization_history_fig.write_image(f\"{optuna_fig_path}/optimization_history_fig.svg\", format='svg', scale=2, width=700, height=500) if not in_notebook() else None\n",
    "\n",
    "# Pareto 前沿图（仅适用于多目标优化）\n",
    "if len(study.directions) > 1:\n",
    "    pareto_fig = plot_pareto_front(study, **targets_args)\n",
    "    pareto_fig.update_layout(width=1200, height=800)\n",
    "    pareto_fig.show() if in_notebook() else None\n",
    "    pareto_fig.write_image(f\"{optuna_fig_path}/pareto_fig.svg\", format='svg', scale=2, width=1200, height=1200) if not in_notebook() else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手动调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, W_train, y_train = load_data(df_train)\n",
    "# X_test, W_test, y_test = load_data(df_test)\n",
    "\n",
    "# # modified GANITE\n",
    "# model = Ganite(dim_in=X.shape[1],\n",
    "#                binary_y=True,\n",
    "#                dim_hidden=300,\n",
    "#                alpha = 0.3,\n",
    "#                beta = 0.3,\n",
    "#                depth = 3,\n",
    "#                minibatch_size = 200,\n",
    "#                num_iterations=2500,\n",
    "#                num_discr_iterations=3,\n",
    "#                )\n",
    "\n",
    "# if RUN_MODE == 'train':\n",
    "#     model = model.fit(X_train, W_train, y_train)\n",
    "#     torch.save(model.state_dict(), f\"{MODELS}/GANITE.pth\")\n",
    "# else:\n",
    "#     model.load_state_dict(torch.load(f\"{MODELS}/GANITE_best_weights_manual.pth\", weights_only=True))\n",
    "#     model.eval()  # 切换到评估模式（重要！）\n",
    "#     print(\"模型参数已加载！\")\n",
    "\n",
    "# # 测试集测试\n",
    "# Y_1_test, Y_0_test, ITE_test = model(X_test)\n",
    "# df_test['potential_y1'] = Y_1_test.cpu()\n",
    "# df_test['potential_y0'] = Y_0_test.cpu()\n",
    "# df_test['ITE'] = ITE_test.cpu()\n",
    "# df_test['y_pred_observed'] = df_test.apply(lambda row: row['potential_y1'] if row[treatment]==1 else row['potential_y0'], axis=1)\n",
    "\n",
    "# ATE_test = RCT_ATE(df_test[treatment], df_test[current_outcome])\n",
    "# ATE_pred_ob = RCT_ATE(df_test[treatment], df_test['y_pred_observed'])\n",
    "# ATE_pred = df_test['ITE'].mean()\n",
    "\n",
    "# print(f'实际ATE: {ATE_test:.4f}, 预测实际ATE: {ATE_pred_ob:.4f}, ATE误差: {ATE_test - ATE_pred_ob:.4f}, 预测组间ATE: {ATE_pred:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
