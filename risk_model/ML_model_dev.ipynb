{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39c47fd-fc1c-4a35-bedc-4740b2d888f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cpu\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "训练机器学习模型，预测 28天死亡率及院内死亡率\n",
    "'''\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "# 检测运行环境\n",
    "IN_NOTEBOOK = None\n",
    "def in_notebook():\n",
    "    return 'IPKernelApp' in getattr(globals().get('get_ipython', lambda: None)(), 'config', {})\n",
    "    \n",
    "if in_notebook():\n",
    "    from IPython.display import clear_output, display\n",
    "    notebook_dir = os.getcwd()\n",
    "    src_path = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "    IN_NOTEBOOK = True\n",
    "else:\n",
    "    src_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    sys_args = parser.parse_args()\n",
    "    IN_NOTEBOOK = False\n",
    "\n",
    "sys.path.append(src_path) if src_path not in sys.path else None\n",
    "\n",
    "from src.utils import *\n",
    "from src.model_utils import *\n",
    "from src.metrix import cal_ci, format_ci\n",
    "from src.setup import *\n",
    "from risk_setup import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'current device: {DEVICE}')\n",
    "risk_ml_models = f'{MODELS}/risk_models/ML_ref_model/'\n",
    "os.makedirs(risk_ml_models, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93932f01-ff22-4b69-a7bc-0c831161518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (2001, 31)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATA}/imputed/MIMIC_IV_clean_imputed.tsv.gz', sep='\\t', index_col='ID')\n",
    "df = df.sample(frac=0.1) if IN_NOTEBOOK else df\n",
    "features, _, _, outcomes = get_risk_model_features()\n",
    "X, y = load_data(df, outcome_ix=0) # 这里加载了 28-d mortality 作为预测目标\n",
    "\n",
    "# load multi-task y\n",
    "y = df[outcomes].copy() \n",
    "\n",
    "# standardization of X\n",
    "std_processor = StandardScaler()\n",
    "X_array = std_processor.fit_transform(X)\n",
    "X = pd.DataFrame(X_array, index=X.index, columns=X.columns)\n",
    "joblib.dump(std_processor, f'{risk_ml_models}/MIMIC_StandardScaler.joblib')\n",
    "\n",
    "print(f'training data: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33173ed3-f0c5-4ffa-9d4a-9e1f0a96eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a stacking of LR, KNN, SVM, XGB, and RF\n",
    "base_estimators = [('LR', LogisticRegression(penalty='l2', random_state=19960816)),\n",
    "                   ('KNN', KNeighborsClassifier()),\n",
    "                   ('SVM', SVC(probability=True, random_state=19960816)),\n",
    "                   ('RF', RandomForestClassifier(max_depth=np.log2(X.shape[1]), bootstrap=True, n_jobs=-1, random_state=19960816)),\n",
    "                   ('XGB', XGBClassifier(n_estimators=100, n_jobs=-1, device=DEVICE, random_state=19960816))\n",
    "                  ]\n",
    "\n",
    "# stacking of base models\n",
    "stacking_model = StackingClassifier(base_estimators,\n",
    "                                    final_estimator=LogisticRegression(random_state=19960816), # learn weights for each base estimator\n",
    "                                    stack_method='predict_proba',\n",
    "                                    n_jobs=-1,\n",
    "                                    passthrough=False,\n",
    "                                    verbose=1)\n",
    "\n",
    "# Multi-task Model\n",
    "multi_task_model = MultiOutputClassifier(stacking_model, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e54e9-c6f7-40cd-be91-5dbd3072df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation (performance estimation)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=19960816)\n",
    "aucs_1 = []\n",
    "aucs_2 = []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X, y.iloc[:,0])): # stratified by primary outcome (28d-mortality)\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    # train\n",
    "    multi_task_model.fit(X_train, y_train)\n",
    "    \n",
    "    # eval\n",
    "    y_hat_1 = multi_task_model.predict_proba(X_val)[0][:, 1] # predict proba for 28d-mortality\n",
    "    y_hat_2 = multi_task_model.predict_proba(X_val)[1][:, 1] # predict proba for in-hospital mortality\n",
    "    \n",
    "    y_val_1 = np.array(y_val.iloc[:, 0]) # true 28d-death label\n",
    "    y_val_2 = np.array(y_val.iloc[:, 1]) # true in-hospital death label\n",
    "    \n",
    "    auc_1 = roc_auc_score(y_val_1, y_hat_1)\n",
    "    auc_2 = roc_auc_score(y_val_2, y_hat_2)\n",
    "    \n",
    "    aucs_1.append(auc_1)\n",
    "    aucs_2.append(auc_2)\n",
    "    \n",
    "    print(f'Fold {i+1}: AUC of y1: {auc_1:.3f}, AUC of y2: {auc_2:.3f}')\n",
    "\n",
    "# assume t-distribution for 95% CI calculation\n",
    "mean_auc_1, lower_1, upper_1 = cal_ci(aucs_1, alpha=0.05, method='t')\n",
    "mean_auc_2, lower_2, upper_2 = cal_ci(aucs_2, alpha=0.05, method='t')\n",
    "print(f'AUC of {outcomes[0]}: {format_ci(mean_auc_1, lower_1, upper_1, 3)}')\n",
    "print(f'AUC of {outcomes[1]}: {format_ci(mean_auc_2, lower_2, upper_2, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee7f36-bb05-4bdf-b929-c847322a2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train reference model on whole training set and save for external validation.\n",
    "multi_task_model.fit(X, y)\n",
    "joblib.dump(multi_task_model, f'{risk_ml_models}/MIMIC_stacking.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
