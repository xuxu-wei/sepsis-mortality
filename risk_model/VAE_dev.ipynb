{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39c47fd-fc1c-4a35-bedc-4740b2d888f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run in notebook\n",
      "current device: cuda\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "训练Hybrid VAE，预测 28天死亡率及院内死亡率\n",
    "'''\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_parallel_coordinate,\n",
    "    plot_param_importances,\n",
    "    plot_contour,\n",
    "    plot_slice,\n",
    "    plot_optimization_history,\n",
    "    plot_pareto_front,\n",
    ")\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "sns.set_theme('paper')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "# 检测运行环境\n",
    "IN_NOTEBOOK = None\n",
    "def in_notebook():\n",
    "    return 'IPKernelApp' in getattr(globals().get('get_ipython', lambda: None)(), 'config', {})\n",
    "    \n",
    "if in_notebook():\n",
    "    IN_NOTEBOOK = True\n",
    "    print('run in notebook')\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    from IPython.display import clear_output, display\n",
    "    notebook_dir = os.getcwd()\n",
    "    src_path = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "    RUN_MODE = 'tuning' # reload: 重现study; tuning 搜索超参数\n",
    "    N_TRIAL = 100\n",
    "else:\n",
    "    IN_NOTEBOOK = False\n",
    "    print('run in script')\n",
    "    src_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    parser.add_argument('-n', metavar= 50, type=int, default=50,help='''optuna优化尝试次数''')\n",
    "    sys_args = parser.parse_args()\n",
    "    N_TRIAL = sys_args.n\n",
    "    RUN_MODE = 'tuning' # 脚本模式只做tuing!\n",
    "\n",
    "sys.path.append(src_path) if src_path not in sys.path else None\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "from src.utils import *\n",
    "from src.model_utils import to_numpy, check_tensor\n",
    "from src.metrix import cal_ci, format_ci\n",
    "from src.setup import *\n",
    "from risk_setup import *\n",
    "from risk_model.HybridVAE import HybridVAEMultiTaskSklearn\n",
    "\n",
    "set_random_seed(19960816)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'current device: {DEVICE}')\n",
    "risk_hybrid_vae = f'{MODELS}/risk_models/Hybrid_VAE_model/'\n",
    "os.makedirs(risk_hybrid_vae, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93932f01-ff22-4b69-a7bc-0c831161518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (2001, 31)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATA}/imputed/MIMIC_IV_clean_imputed.tsv.gz', sep='\\t', index_col='ID')\n",
    "df = df.sample(frac=0.1) if IN_NOTEBOOK else df\n",
    "features, _, _, outcomes = get_risk_model_features()\n",
    "X, y = load_data(df, outcome_ix=0) # 这里加载了 28-d mortality 作为预测目标\n",
    "\n",
    "# load multi-task y\n",
    "y = df[outcomes].copy() \n",
    "\n",
    "# standardization of X\n",
    "std_processor = StandardScaler()\n",
    "X_array = std_processor.fit_transform(X)\n",
    "X = pd.DataFrame(X_array, index=X.index, columns=X.columns)\n",
    "joblib.dump(std_processor, f'{risk_hybrid_vae}/MIMIC_StandardScaler.joblib')\n",
    "\n",
    "print(f'training data: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894a420",
   "metadata": {},
   "source": [
    "# Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d88d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if IN_NOTEBOOK:\n",
    "#     kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=19960816)\n",
    "#     aucs_1 = []\n",
    "#     aucs_2 = []\n",
    "#     for i, (train_index, val_index) in enumerate(kf.split(X, y.iloc[:,0])):\n",
    "#         # 划分训练集和验证集\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "#         model = HybridVAEMultiTaskSklearn(input_dim=X_train.shape[1],\n",
    "#                                         task_count=y_train.shape[1],\n",
    "#                                         layer_strategy='l',\n",
    "#                                         vae_hidden_dim=50,\n",
    "#                                         vae_depth=1,\n",
    "#                                         vae_dropout_rate=0.3,\n",
    "#                                         latent_dim=10,\n",
    "#                                         predictor_hidden_dim=20,\n",
    "#                                         predictor_depth=1,\n",
    "#                                         task_hidden_dim=20,\n",
    "#                                         task_depth=1,\n",
    "#                                         predictor_dropout_rate=0.3,\n",
    "#                                         vae_lr=1e-3,\n",
    "#                                         vae_weight_decay=1e-3,\n",
    "#                                         multitask_lr=1e-3,\n",
    "#                                         multitask_weight_decay=1e-3,\n",
    "#                                         alphas=None,\n",
    "#                                         beta=1.0,\n",
    "#                                         gamma_task=10000.0,\n",
    "#                                         batch_size=500,\n",
    "#                                         validation_split=0.2,\n",
    "#                                         use_lr_scheduler=True,\n",
    "#                                         lr_scheduler_factor=0.2,\n",
    "#                                         lr_scheduler_patience=25,\n",
    "#                                         use_batch_norm=True,\n",
    "#                                         )\n",
    "\n",
    "#         model = model.fit(X_train, y_train,\n",
    "#                         epochs=2000, \n",
    "#                         early_stopping=True, \n",
    "#                         patience=100,\n",
    "#                         verbose=2, \n",
    "#                         animate_monitor=True,\n",
    "#                         plot_path=None,\n",
    "#                         save_weights_path=None\n",
    "#                         )\n",
    "\n",
    "#         auc1, auc2 = model.score(X_val, y_val)\n",
    "#         aucs_1.append(auc1)\n",
    "#         aucs_2.append(auc2)\n",
    "        \n",
    "#     # assume t-distribution for 95% CI calculation\n",
    "#     mean_auc_1, lower_1, upper_1 = cal_ci(aucs_1, alpha=0.05, method='t')\n",
    "#     mean_auc_2, lower_2, upper_2 = cal_ci(aucs_2, alpha=0.05, method='t')\n",
    "#     print(f'AUC of {outcomes[0]}: {format_ci(mean_auc_1, lower_1, upper_1, 3)}')\n",
    "#     print(f'AUC of {outcomes[1]}: {format_ci(mean_auc_2, lower_2, upper_2, 3)}')\n",
    "    \n",
    "#     total_loss, recon_loss, kl_loss, task_loss = model.eval_loss(X_val, y_val)\n",
    "#     print(f'Losses on last fold: {total_loss=:.4f}, {recon_loss=:.4f}, {kl_loss=:.4f}, {task_loss=:.4f}')\n",
    "#     print(summary(model, input_size=(model.batch_size, X.shape[1])))\n",
    "# \n",
    "# # AUC of 28d_mortality: 0.762 (0.717 - 0.807)\n",
    "# # AUC of in_hospital_mortality: 0.765 (0.738 - 0.793)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a071ea",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d01615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>values_0</th>\n",
       "      <th>values_1</th>\n",
       "      <th>values_2</th>\n",
       "      <th>values_3</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_beta</th>\n",
       "      <th>params_gamma_task</th>\n",
       "      <th>params_latent_dim</th>\n",
       "      <th>params_layer_strategy</th>\n",
       "      <th>params_lr_scheduler_factor</th>\n",
       "      <th>params_lr_scheduler_patience</th>\n",
       "      <th>params_multitask_lr</th>\n",
       "      <th>params_multitask_weight_decay</th>\n",
       "      <th>params_predictor_depth</th>\n",
       "      <th>params_predictor_dropout_rate</th>\n",
       "      <th>params_predictor_hidden_dim</th>\n",
       "      <th>params_task_depth</th>\n",
       "      <th>params_task_hidden_dim</th>\n",
       "      <th>params_use_batch_norm</th>\n",
       "      <th>params_use_lr_scheduler</th>\n",
       "      <th>params_vae_depth</th>\n",
       "      <th>params_vae_dropout_rate</th>\n",
       "      <th>params_vae_hidden_dim</th>\n",
       "      <th>params_vae_lr</th>\n",
       "      <th>params_vae_weight_decay</th>\n",
       "      <th>params_validation_split</th>\n",
       "      <th>system_attrs_nsga2:generation</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.654731</td>\n",
       "      <td>0.642065</td>\n",
       "      <td>34.148222</td>\n",
       "      <td>21.904548</td>\n",
       "      <td>2024-12-08 22:09:16.082712</td>\n",
       "      <td>2024-12-08 22:15:51.355791</td>\n",
       "      <td>0 days 00:06:35.273079</td>\n",
       "      <td>300</td>\n",
       "      <td>2.7</td>\n",
       "      <td>621.511462</td>\n",
       "      <td>7</td>\n",
       "      <td>l</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.539793</td>\n",
       "      <td>0.564552</td>\n",
       "      <td>44.244418</td>\n",
       "      <td>31.131712</td>\n",
       "      <td>2024-12-08 22:15:51.395321</td>\n",
       "      <td>2024-12-08 22:22:02.943788</td>\n",
       "      <td>0 days 00:06:11.548467</td>\n",
       "      <td>300</td>\n",
       "      <td>2.2</td>\n",
       "      <td>27.471141</td>\n",
       "      <td>14</td>\n",
       "      <td>l</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2024-12-08 22:22:02.969044</td>\n",
       "      <td>2024-12-08 22:22:03.021287</td>\n",
       "      <td>0 days 00:00:00.052243</td>\n",
       "      <td>900</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4265.696246</td>\n",
       "      <td>15</td>\n",
       "      <td>c</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.45</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.469691</td>\n",
       "      <td>0.500248</td>\n",
       "      <td>37.501047</td>\n",
       "      <td>21.877183</td>\n",
       "      <td>2024-12-08 22:22:03.044815</td>\n",
       "      <td>2024-12-08 22:25:45.078683</td>\n",
       "      <td>0 days 00:03:42.033868</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.272815</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>190</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  values_0  values_1   values_2   values_3  \\\n",
       "0       0  0.654731  0.642065  34.148222  21.904548   \n",
       "1       1  0.539793  0.564552  44.244418  31.131712   \n",
       "2       2      -inf      -inf        inf        inf   \n",
       "3       3  0.469691  0.500248  37.501047  21.877183   \n",
       "\n",
       "              datetime_start          datetime_complete  \\\n",
       "0 2024-12-08 22:09:16.082712 2024-12-08 22:15:51.355791   \n",
       "1 2024-12-08 22:15:51.395321 2024-12-08 22:22:02.943788   \n",
       "2 2024-12-08 22:22:02.969044 2024-12-08 22:22:03.021287   \n",
       "3 2024-12-08 22:22:03.044815 2024-12-08 22:25:45.078683   \n",
       "\n",
       "                duration  params_batch_size  params_beta  params_gamma_task  \\\n",
       "0 0 days 00:06:35.273079                300          2.7         621.511462   \n",
       "1 0 days 00:06:11.548467                300          2.2          27.471141   \n",
       "2 0 days 00:00:00.052243                900          4.0        4265.696246   \n",
       "3 0 days 00:03:42.033868                300          5.0           7.272815   \n",
       "\n",
       "   params_latent_dim params_layer_strategy  params_lr_scheduler_factor  \\\n",
       "0                  7                     l                         0.2   \n",
       "1                 14                     l                         0.2   \n",
       "2                 15                     c                         0.2   \n",
       "3                 11                     c                         0.1   \n",
       "\n",
       "   params_lr_scheduler_patience  params_multitask_lr  \\\n",
       "0                            25             0.000011   \n",
       "1                            25             0.000079   \n",
       "2                            50             0.000716   \n",
       "3                            50             0.000723   \n",
       "\n",
       "   params_multitask_weight_decay  params_predictor_depth  \\\n",
       "0                       0.001027                       1   \n",
       "1                       0.005318                       2   \n",
       "2                       0.000110                       2   \n",
       "3                       0.001182                       1   \n",
       "\n",
       "   params_predictor_dropout_rate  params_predictor_hidden_dim  \\\n",
       "0                           0.35                           40   \n",
       "1                           0.15                           10   \n",
       "2                           0.45                           60   \n",
       "3                           0.50                           40   \n",
       "\n",
       "   params_task_depth  params_task_hidden_dim  params_use_batch_norm  \\\n",
       "0                  1                      20                   True   \n",
       "1                  2                      30                  False   \n",
       "2                  0                      10                   True   \n",
       "3                  1                      30                  False   \n",
       "\n",
       "   params_use_lr_scheduler  params_vae_depth  params_vae_dropout_rate  \\\n",
       "0                    False                 0                     0.05   \n",
       "1                    False                 1                     0.35   \n",
       "2                    False                 2                     0.30   \n",
       "3                     True                 2                     0.05   \n",
       "\n",
       "   params_vae_hidden_dim  params_vae_lr  params_vae_weight_decay  \\\n",
       "0                     70       0.000026                 0.004309   \n",
       "1                    150       0.000379                 0.000020   \n",
       "2                    120       0.000062                 0.000031   \n",
       "3                    190       0.000176                 0.000011   \n",
       "\n",
       "   params_validation_split  system_attrs_nsga2:generation     state  \n",
       "0                      0.4                              0  COMPLETE  \n",
       "1                      0.3                              0  COMPLETE  \n",
       "2                      0.3                              0  COMPLETE  \n",
       "3                      0.2                              0  COMPLETE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pareto optimal solutions: 2\n",
      "Pareto solution 0: Values [0.6547314376303554, 0.6420650501150776, 34.148221839383474, 21.904547525229894], Params {'layer_strategy': 'l', 'vae_hidden_dim': 70, 'vae_depth': 0, 'vae_dropout_rate': 0.05, 'latent_dim': 7, 'predictor_hidden_dim': 40, 'predictor_depth': 1, 'task_hidden_dim': 20, 'task_depth': 1, 'predictor_dropout_rate': 0.35000000000000003, 'vae_lr': 2.56392017331631e-05, 'vae_weight_decay': 0.00430876004783913, 'multitask_lr': 1.1344234265835241e-05, 'multitask_weight_decay': 0.001026603003516424, 'beta': 2.7, 'gamma_task': 621.5114617976119, 'batch_size': 300, 'validation_split': 0.4, 'use_lr_scheduler': False, 'lr_scheduler_factor': 0.2, 'lr_scheduler_patience': 25, 'use_batch_norm': True}\n",
      "Pareto solution 1: Values [0.4696914911017494, 0.5002481679030432, 37.501047165868286, 21.877183422060085], Params {'layer_strategy': 'c', 'vae_hidden_dim': 190, 'vae_depth': 2, 'vae_dropout_rate': 0.05, 'latent_dim': 11, 'predictor_hidden_dim': 40, 'predictor_depth': 1, 'task_hidden_dim': 30, 'task_depth': 1, 'predictor_dropout_rate': 0.5, 'vae_lr': 0.00017649005221070322, 'vae_weight_decay': 1.1154849842472582e-05, 'multitask_lr': 0.0007225609176928367, 'multitask_weight_decay': 0.0011821994488747964, 'beta': 5.0, 'gamma_task': 7.272815020888162, 'batch_size': 300, 'validation_split': 0.2, 'use_lr_scheduler': True, 'lr_scheduler_factor': 0.1, 'lr_scheduler_patience': 50, 'use_batch_norm': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  65%|█▉ | 1306/2000 [01:09<00:36, 18.79epoch/s, Train VAE Loss=20.7551, Val VAE Loss=21.0979, Train Task Loss=0.0033, Val Task Loss=0.0067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered due to no improvement in both VAE and task losses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  77%|██▎| 1532/2000 [01:21<00:24, 18.82epoch/s, Train VAE Loss=20.6527, Val VAE Loss=20.6420, Train Task Loss=0.0032, Val Task Loss=0.0056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered due to no improvement in both VAE and task losses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  31%|█▎  | 628/2000 [00:33<01:12, 18.85epoch/s, Train VAE Loss=24.4629, Val VAE Loss=23.3441, Train Task Loss=0.0041, Val Task Loss=0.0047]"
     ]
    }
   ],
   "source": [
    "if RUN_MODE=='tuning':\n",
    "\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            # 定义需要调优的超参数范围\n",
    "            # network structure\n",
    "            layer_strategy = trial.suggest_categorical(\"layer_strategy\", ['c', 'l', 'g'])\n",
    "            vae_hidden_dim = trial.suggest_int(\"vae_hidden_dim\", 20, 200, step=10)\n",
    "            vae_depth = trial.suggest_int(\"vae_depth\", 0, 3, step=1)\n",
    "            vae_dropout_rate = trial.suggest_float(\"vae_dropout_rate\", 0.05, 0.5, step=0.05)\n",
    "            latent_dim = trial.suggest_int(\"latent_dim\", 5, 15, step=1)\n",
    "            predictor_hidden_dim = trial.suggest_int(\"predictor_hidden_dim\", 10, 100, step=10)\n",
    "            predictor_depth = trial.suggest_int(\"predictor_depth\", 0, 2, step=1)\n",
    "            task_hidden_dim =  trial.suggest_int(\"task_hidden_dim\", 10, 30, step=5)\n",
    "            task_depth = trial.suggest_int(\"task_depth\", 0, 2, step=1)\n",
    "            predictor_dropout_rate = trial.suggest_float(\"predictor_dropout_rate\", 0.05, 0.5, step=0.05)\n",
    "            # learning and normalization\n",
    "            vae_lr = trial.suggest_float(\"vae_lr\", 1e-5, 1e-3, log=True)\n",
    "            vae_weight_decay = trial.suggest_float(\"vae_weight_decay\", 1e-5, 1e-2, log=True)\n",
    "            multitask_lr = trial.suggest_float(\"multitask_lr\", 1e-5, 1e-3, log=True)\n",
    "            multitask_weight_decay = trial.suggest_float(\"multitask_weight_decay\", 1e-5, 1e-2, log=True)\n",
    "            beta = trial.suggest_float(\"beta\", 1.0, 5.0, step=0.1)\n",
    "            gamma_task = trial.suggest_float(\"gamma_task\", 1.0, 100000, log=True) \n",
    "            batch_size = trial.suggest_int(\"batch_size\", 200, 1000, step=100)\n",
    "            validation_split = trial.suggest_categorical(\"validation_split\", [0.2, 0.3, 0.4])\n",
    "            use_lr_scheduler = trial.suggest_categorical(\"use_lr_scheduler\", [True, False])\n",
    "            lr_scheduler_factor = trial.suggest_categorical(\"lr_scheduler_factor\", [0.1, 0.2])\n",
    "            fit_patience = 100\n",
    "            lr_scheduler_patience = trial.suggest_categorical(\"lr_scheduler_patience\", [int(fit_patience/2), int(fit_patience/3), int(fit_patience/4),])\n",
    "            use_batch_norm = trial.suggest_categorical(\"use_batch_norm\", [True, False])\n",
    "            # 初始化模型\n",
    "            model = HybridVAEMultiTaskSklearn(input_dim=X.shape[1],\n",
    "                                            task_count=y.shape[1],\n",
    "                                            layer_strategy=layer_strategy,\n",
    "                                            vae_hidden_dim=vae_hidden_dim,\n",
    "                                            vae_depth=vae_depth,\n",
    "                                            vae_dropout_rate=vae_dropout_rate,\n",
    "                                            latent_dim=latent_dim,\n",
    "                                            predictor_hidden_dim=predictor_hidden_dim,\n",
    "                                            predictor_depth=predictor_depth,\n",
    "                                            task_hidden_dim=task_hidden_dim,\n",
    "                                            task_depth=task_depth,\n",
    "                                            predictor_dropout_rate=predictor_dropout_rate,\n",
    "                                            vae_lr=vae_lr,\n",
    "                                            vae_weight_decay=vae_weight_decay,\n",
    "                                            multitask_lr=multitask_lr,\n",
    "                                            multitask_weight_decay=multitask_weight_decay,\n",
    "                                            alphas=None,\n",
    "                                            beta=beta,\n",
    "                                            gamma_task=gamma_task,\n",
    "                                            batch_size=batch_size,\n",
    "                                            validation_split=validation_split,\n",
    "                                            use_lr_scheduler=use_lr_scheduler,\n",
    "                                            lr_scheduler_factor=lr_scheduler_factor,\n",
    "                                            lr_scheduler_patience=lr_scheduler_patience,\n",
    "                                            use_batch_norm=use_batch_norm,\n",
    "                                            )\n",
    "            # 实现交叉验证\n",
    "            kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=19960816)\n",
    "            aucs_1 = []\n",
    "            aucs_2 = []\n",
    "            recon_losses = []\n",
    "            vae_losses = []\n",
    "\n",
    "            for i, (train_index, val_index) in enumerate(kf.split(X, y.iloc[:,0])): # stratified by primary outcome\n",
    "                # 划分训练集和验证集\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "                \n",
    "                # 训练模型\n",
    "                model.fit(X_train, y_train,\n",
    "                            epochs=2000, \n",
    "                            early_stopping=True, \n",
    "                            patience=fit_patience,\n",
    "                            verbose=1, \n",
    "                            animate_monitor=False,\n",
    "                            plot_path=None,\n",
    "                            save_weights_path=None)\n",
    "                \n",
    "                # 验证模型并记录分数\n",
    "                auc1, auc2 = model.score(X_val, y_val)  # 默认AUC\n",
    "                total_loss, recon_loss, kl_loss, task_loss = model.eval_loss(X_val, y_val)\n",
    "                vae_loss = recon_loss + model.beta * kl_loss\n",
    "\n",
    "                aucs_1.append(auc1)\n",
    "                aucs_2.append(auc2)\n",
    "                recon_losses.append(recon_loss)\n",
    "                vae_losses.append(vae_loss)\n",
    "\n",
    "            # 返回平均交叉验证分数（负均方误差）\n",
    "            return np.mean(aucs_1), np.mean(aucs_2), np.mean(vae_losses), np.mean(recon_losses)\n",
    "        except Exception as e:\n",
    "            print(f\"Trial failed with error: {e}\")\n",
    "            return -np.inf, -np.inf, np.inf, np.inf\n",
    "\n",
    "\n",
    "    # 日志功能：设置 Optuna 的日志级别\n",
    "    # optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "    # 实时打印当前最佳结果\n",
    "    def trial_callback(study, trial):\n",
    "        is_multiobjective = len(study.directions) > 1  # 判断是否多目标优化\n",
    "\n",
    "        if is_multiobjective:\n",
    "            pareto_front = study.best_trials  # 获取 Pareto 前沿解\n",
    "\n",
    "            if IN_NOTEBOOK:\n",
    "                clear_output(wait=True)  # 清除之前的输出\n",
    "                df_trials = study.trials_dataframe()  # 获取当前的试验数据\n",
    "                display(df_trials)  # 动态显示最新的 dataframe\n",
    "\n",
    "                # 打印 Pareto 前沿解的信息\n",
    "                print(f\"Number of Pareto optimal solutions: {len(pareto_front)}\")\n",
    "                for i, pareto_trial in enumerate(pareto_front):\n",
    "                    print(f\"Pareto solution {i}: Values {pareto_trial.values}, Params {pareto_trial.params}\")\n",
    "            else:\n",
    "                best_trial = pareto_front[0]  # 选择首选 Pareto 前沿解\n",
    "                print(\n",
    "                    f\"Trial {trial.number}/{N_TRIAL} finished with value: {trial.values} and parameters: {trial.params} | \"\n",
    "                    f\"Current best value: {best_trial.values} and parameters: {best_trial.params} | \"\n",
    "                    f\"Number of Pareto optimal solutions: {len(pareto_front)}\"\n",
    "                )\n",
    "        else:\n",
    "            if IN_NOTEBOOK:\n",
    "                clear_output(wait=True)  # 清除之前的输出\n",
    "                df_trials = study.trials_dataframe()  # 获取当前的试验数据\n",
    "                display(df_trials)  # 动态显示最新的 dataframe\n",
    "\n",
    "                # 打印当前最优解的信息\n",
    "                print(f\"Current best value: {study.best_value}\")\n",
    "                print(f\"Current best parameters: {study.best_params}\")\n",
    "                print(f\"Current best trial: {study.best_trials}\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Trial {trial.number}/{N_TRIAL} finished with value: {trial.value} and parameters: {trial.params} | \"\n",
    "                    f\"Current best value: {study.best_value} and parameters: {study.best_params}\"\n",
    "                )\n",
    "                \n",
    "    # 使用 Optuna 优化\n",
    "    study = optuna.create_study(directions=[\"maximize\", \"maximize\", \"minimize\", 'minimize'], sampler=optuna.samplers.NSGAIISampler(seed=1))  # 或 \"minimize\"，取决于评分标准\n",
    "    study.optimize(objective, n_trials=N_TRIAL, callbacks=[trial_callback])\n",
    "\n",
    "    # 保存实验结果\n",
    "    with open(f\"{risk_hybrid_vae}/optuna_study.pkl\", \"wb\") as f:\n",
    "        print('调参结束，正在保存optuna调参试验结果')\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "    # 获取 Pareto 前沿解\n",
    "    pareto_front = study.best_trials\n",
    "    print(\"Pareto Front Solutions:\")\n",
    "    for trial in pareto_front:\n",
    "        print(f\"Trial {trial.number}: Values {trial.values}, Params {trial.params}\")\n",
    "\n",
    "    # 保存 Pareto 解到文件\n",
    "    pareto_data = [\n",
    "        {\"trial_number\": trial.number, \"values\": trial.values, \"params\": trial.params}\n",
    "        for trial in pareto_front\n",
    "    ]\n",
    "    with open(f\"{risk_hybrid_vae}/pareto_solutions.json\", \"w\") as f:\n",
    "        json.dump(pareto_data, f)\n",
    "\n",
    "\n",
    "    # 保存完整调参历史为 xlsx 文件\n",
    "    df_trials = study.trials_dataframe()\n",
    "    df_trials.to_excel(f\"{risk_hybrid_vae}/tuning_history.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb1692-dfa8-4ba6-bea8-f84df5763f55",
   "metadata": {},
   "source": [
    "# Training with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb058862-33cc-4901-b0cd-906bc9f7c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE=='tuning':\n",
    "    pass\n",
    "\n",
    "elif RUN_MODE=='reload':\n",
    "    with open(f\"{risk_hybrid_vae}/optuna_study.pkl\", \"rb\") as f:\n",
    "        print('正在加载指定optuna调参试验结果')\n",
    "        study = pickle.load(f)\n",
    "        \n",
    "# 使用一个 Pareto 最优解重新初始化模型\n",
    "pareto_front = study.best_trials\n",
    "best_trial = pareto_front[0] # 选择第一个 Pareto 解\n",
    "best_params = best_trial.params\n",
    "\n",
    "# 使用最佳参数重新初始化模型\n",
    "best_model = HybridVAEMultiTaskSklearn(input_dim=X.shape[1], task_count=y.shape[1], **best_params)\n",
    "\n",
    "# 训练最佳模型\n",
    "print('使用最佳参数进行内部验证估计误差')\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=19960816)\n",
    "aucs_1 = []\n",
    "aucs_2 = []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X, y.iloc[:,0])):\n",
    "    # 划分训练集和验证集\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model = HybridVAEMultiTaskSklearn(input_dim=X_train.shape[1],\n",
    "                                    task_count=y_train.shape[1],\n",
    "                                    layer_strategy='l',\n",
    "                                    vae_hidden_dim=50,\n",
    "                                    vae_depth=1,\n",
    "                                    vae_dropout_rate=0.3,\n",
    "                                    latent_dim=10,\n",
    "                                    predictor_hidden_dim=20,\n",
    "                                    predictor_depth=1,\n",
    "                                    task_hidden_dim=20,\n",
    "                                    task_depth=1,\n",
    "                                    predictor_dropout_rate=0.3,\n",
    "                                    vae_lr=1e-3,\n",
    "                                    vae_weight_decay=1e-3,\n",
    "                                    multitask_lr=1e-3,\n",
    "                                    multitask_weight_decay=1e-3,\n",
    "                                    alphas=None,\n",
    "                                    beta=1.0,\n",
    "                                    gamma_task=10000.0,\n",
    "                                    batch_size=256,\n",
    "                                    validation_split=0.2,\n",
    "                                    use_lr_scheduler=True,\n",
    "                                    lr_scheduler_factor=0.2,\n",
    "                                    lr_scheduler_patience=25,\n",
    "                                    use_batch_norm=True,\n",
    "                                    )\n",
    "\n",
    "    model = model.fit(X_train, y_train,\n",
    "                    epochs=2000, \n",
    "                    early_stopping=True, \n",
    "                    patience=100,\n",
    "                    verbose=2, \n",
    "                    animate_monitor=True,\n",
    "                    plot_path=None,\n",
    "                    save_weights_path=None\n",
    "                    )\n",
    "\n",
    "    auc1, auc2 = model.score(X_val, y_val)\n",
    "    aucs_1.append(auc1)\n",
    "    aucs_2.append(auc2)\n",
    "\n",
    "# assume t-distribution for 95% CI calculation\n",
    "mean_auc_1, lower_1, upper_1 = cal_ci(aucs_1, alpha=0.05, method='t')\n",
    "mean_auc_2, lower_2, upper_2 = cal_ci(aucs_2, alpha=0.05, method='t')\n",
    "print(f'AUC of {outcomes[0]}: {format_ci(mean_auc_1, lower_1, upper_1, 3)}')\n",
    "print(f'AUC of {outcomes[1]}: {format_ci(mean_auc_2, lower_2, upper_2, 3)}')\n",
    "\n",
    "total_loss, recon_loss, kl_loss, task_loss = model.eval_loss(X_val, y_val)\n",
    "print(f'Losses on last fold: {total_loss=:.4f}, {recon_loss=:.4f}, {kl_loss=:.4f}, {task_loss=:.4f}')\n",
    "print(summary(model, input_size=(model.batch_size, X.shape[1])))\n",
    "\n",
    "print('使用最佳参数在全集上训练模型 （准备外部验证）')\n",
    "best_model.fit(X, y,\n",
    "                epochs=2000, \n",
    "                early_stopping=True, \n",
    "                patience=200,\n",
    "                verbose=2, \n",
    "                animate_monitor=True,\n",
    "                plot_path=risk_hybrid_vae,\n",
    "                save_weights_path=risk_hybrid_vae)\n",
    "\n",
    "print(f'最终AUC: {best_model.score(X, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e43c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制不同的图表\n",
    "target_args_1 = dict(target = lambda t: -t.values[0], target_name=\"AUC-primary\")\n",
    "target_args_2 = dict(target = lambda t: -t.values[1], target_name=\"AUC-secondary\")\n",
    "target_args_3 = dict(target = lambda t: -t.values[2], target_name=\"VAE loss\")\n",
    "target_args_4 = dict(target = lambda t: -t.values[3], target_name=\"Reconstruction MSE\")\n",
    "targets_args = dict(targets = lambda t: [t.values[0], -t.values[2]], target_names=[\"AUC\", \"VAE loss\"])\n",
    "\n",
    "# 并行坐标图\n",
    "parallel_coordinate_fig = plot_parallel_coordinate(study, **target_args_1)\n",
    "parallel_coordinate_fig.update_layout(width=800, height=600)\n",
    "parallel_coordinate_fig.show() if IN_NOTEBOOK else None\n",
    "parallel_coordinate_fig.write_image(f\"{risk_hybrid_vae}/parallel_coordinate_fig.svg\", format='svg', scale=2, width=700, height=500) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 参数重要性图\n",
    "param_importance_fig = plot_param_importances(study, **target_args_1)\n",
    "param_importance_fig.update_layout(width=800, height=600)\n",
    "param_importance_fig.show() if IN_NOTEBOOK else None\n",
    "param_importance_fig.write_image(f\"{risk_hybrid_vae}/param_importance_fig.svg\", format='svg', scale=2, width=700, height=500) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 平行曲面图\n",
    "contour_fig = plot_contour(study, **target_args_1)\n",
    "contour_fig.update_layout(width=1200, height=1200)\n",
    "contour_fig.show() if IN_NOTEBOOK else None\n",
    "contour_fig.write_image(f\"{risk_hybrid_vae}/contour_fig.svg\", format='svg', scale=2, width=1200, height=1200) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 超参数分布图\n",
    "slice_fig = plot_slice(study, **target_args_1)\n",
    "slice_fig.show() if IN_NOTEBOOK else None\n",
    "slice_fig.write_image(f\"{risk_hybrid_vae}/slice_fig.svg\", format='svg', scale=2, width=2500, height=400) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 优化历史图\n",
    "optimization_history_fig = plot_optimization_history(study, **target_args_1)\n",
    "optimization_history_fig.update_layout(width=700, height=500)\n",
    "optimization_history_fig.show() if IN_NOTEBOOK else None\n",
    "optimization_history_fig.write_image(f\"{risk_hybrid_vae}/optimization_history_fig.svg\", format='svg', scale=2, width=700, height=500) if not IN_NOTEBOOK else None\n",
    "\n",
    "# Pareto 前沿图（仅适用于多目标优化）\n",
    "if len(study.directions) > 1:\n",
    "    pareto_fig = plot_pareto_front(study, **targets_args)\n",
    "    pareto_fig.update_layout(width=1200, height=800)\n",
    "    pareto_fig.show() if IN_NOTEBOOK else None\n",
    "    pareto_fig.write_image(f\"{risk_hybrid_vae}/pareto_fig.svg\", format='svg', scale=2, width=1200, height=1200) if not IN_NOTEBOOK else None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
