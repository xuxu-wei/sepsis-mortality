{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c47fd-fc1c-4a35-bedc-4740b2d888f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练Hybrid VAE，预测 28天死亡率及院内死亡率\n",
    "'''\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import torch\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_parallel_coordinate,\n",
    "    plot_param_importances,\n",
    "    plot_contour,\n",
    "    plot_slice,\n",
    "    plot_optimization_history,\n",
    "    plot_pareto_front,\n",
    ")\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "sns.set_theme('paper')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "# 检测运行环境\n",
    "IN_NOTEBOOK = None\n",
    "def in_notebook():\n",
    "    return 'IPKernelApp' in getattr(globals().get('get_ipython', lambda: None)(), 'config', {})\n",
    "    \n",
    "if in_notebook():\n",
    "    IN_NOTEBOOK = True\n",
    "    print('run in notebook')\n",
    "    from IPython.display import clear_output, display\n",
    "    notebook_dir = os.getcwd()\n",
    "    src_path = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "    RUN_MODE = 'tuning' # reload: 重现study; tuning 搜索超参数\n",
    "    N_TRIAL = 5\n",
    "else:\n",
    "    IN_NOTEBOOK = False\n",
    "    print('run in script')\n",
    "    src_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    parser.add_argument('-n', metavar= 50, type=int, default=50,help='''optuna优化尝试次数''')\n",
    "    sys_args = parser.parse_args()\n",
    "    N_TRIAL = sys_args.n\n",
    "    RUN_MODE = 'tuning' # 脚本模式只做tuing!\n",
    "\n",
    "sys.path.append(src_path) if src_path not in sys.path else None\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "from src.utils import *\n",
    "from src.model_utils import to_numpy, check_tensor\n",
    "from src.metrix import cal_ci, format_ci\n",
    "from src.setup import *\n",
    "from risk_setup import *\n",
    "from risk_model.HybridVAE import HybridVAEMultiTaskSklearn\n",
    "\n",
    "set_random_seed(19960816)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'current device: {DEVICE}')\n",
    "risk_hybrid_vae = f'{MODELS}/risk_models/Hybrid_VAE_model/'\n",
    "os.makedirs(risk_hybrid_vae, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93932f01-ff22-4b69-a7bc-0c831161518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA}/imputed/MIMIC_IV_clean_imputed.tsv.gz', sep='\\t', index_col='ID')\n",
    "df = df.sample(frac=0.1) if IN_NOTEBOOK else df\n",
    "features, _, _, outcomes = get_risk_model_features()\n",
    "X, y = load_data(df, outcome_ix=0) # 这里加载了 28-d mortality 作为预测目标\n",
    "\n",
    "# load multi-task y\n",
    "y = df[outcomes].copy() \n",
    "\n",
    "# standardization of X\n",
    "std_processor = StandardScaler()\n",
    "X_array = std_processor.fit_transform(X)\n",
    "X = pd.DataFrame(X_array, index=X.index, columns=X.columns)\n",
    "joblib.dump(std_processor, f'{risk_hybrid_vae}/MIMIC_StandardScaler.joblib')\n",
    "\n",
    "print(f'training data: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a071ea",
   "metadata": {},
   "source": [
    "# 超参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d01615",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE=='tuning':\n",
    "\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            # 定义需要调优的超参数范围\n",
    "            # wide grid\n",
    "            # vae_hidden_dim = trial.suggest_int(\"vae_hidden_dim\", 50, 300, step=10)\n",
    "            # vae_depth = trial.suggest_int(\"vae_depth\", 1, 5, step=1)\n",
    "            # vae_dropout_rate = trial.suggest_float(\"vae_dropout_rate\", 0.0, 0.5, step=0.05)\n",
    "            # latent_dim = trial.suggest_int(\"latent_dim\", 5, 15, step=1)\n",
    "            # predictor_hidden_dim = trial.suggest_int(\"predictor_hidden_dim\", 50, 300, step=10)\n",
    "            # predictor_depth = trial.suggest_int(\"predictor_depth\", 1, 5, step=1)\n",
    "            # predictor_dropout_rate = trial.suggest_float(\"predictor_dropout_rate\", 0.0, 0.5, step=0.05)\n",
    "\n",
    "            # vae_lr = trial.suggest_float(\"vae_lr\", 1e-5, 1e-2, log=True)\n",
    "            # vae_weight_decay = trial.suggest_float(\"vae_weight_decay\", 1e-5, 1e-2, log=True)\n",
    "            # multitask_lr = trial.suggest_float(\"multitask_lr\", 1e-5, 1e-2, log=True)\n",
    "            # multitask_weight_decay = trial.suggest_float(\"multitask_weight_decay\", 1e-5, 1e-2, log=True)\n",
    "            # beta = trial.suggest_float(\"beta\", 1.0, 5.0, step=0.1)\n",
    "            # gamma_task = trial.suggest_float(\"gamma_task\", 1.0, 5.0, step=0.1)\n",
    "            # batch_size = trial.suggest_int(\"batch_size\", 200, 1000, step=100)\n",
    "            # validation_split = trial.suggest_categorical(\"validation_split\", [0.2, 0.3, 0.4])\n",
    "            # use_lr_scheduler = trial.suggest_categorical(\"use_lr_scheduler\", [True, False])\n",
    "            # lr_scheduler_factor = trial.suggest_categorical(\"lr_scheduler_factor\", [0.1, 0.2])\n",
    "            # fit_patience = 200\n",
    "            # lr_scheduler_patience = trial.suggest_categorical(\"lr_scheduler_patience\", [int(fit_patience/2), int(fit_patience/3), int(fit_patience/4),])\n",
    "            # use_batch_norm = trial.suggest_categorical(\"use_batch_norm\", [True, False])\n",
    "\n",
    "            # deep grid\n",
    "            vae_hidden_dim = trial.suggest_int(\"vae_hidden_dim\", 50, 300, step=10)\n",
    "            vae_depth = trial.suggest_int(\"vae_depth\", 1, 5, step=1)\n",
    "            vae_dropout_rate = trial.suggest_float(\"vae_dropout_rate\", 0.0, 0.5, step=0.05)\n",
    "            latent_dim = trial.suggest_int(\"latent_dim\", 5, 15, step=1)\n",
    "            predictor_hidden_dim = trial.suggest_int(\"predictor_hidden_dim\", 50, 300, step=10)\n",
    "            predictor_depth = trial.suggest_int(\"predictor_depth\", 1, 5, step=1)\n",
    "            predictor_dropout_rate = trial.suggest_float(\"predictor_dropout_rate\", 0.0, 0.5, step=0.05)\n",
    "\n",
    "            vae_lr = trial.suggest_float(\"vae_lr\", 1e-5, 1e-2, log=True)\n",
    "            vae_weight_decay = trial.suggest_float(\"vae_weight_decay\", 1e-5, 1e-2, log=True)\n",
    "            multitask_lr = trial.suggest_float(\"multitask_lr\", 1e-5, 1e-2, log=True)\n",
    "            multitask_weight_decay = trial.suggest_float(\"multitask_weight_decay\", 1e-5, 1e-2, log=True)\n",
    "            beta = trial.suggest_float(\"beta\", 1.0, 5.0, step=0.1)\n",
    "            gamma_task = trial.suggest_float(\"gamma_task\", 1.0, 5.0, step=0.1)\n",
    "            batch_size = trial.suggest_int(\"batch_size\", 200, 1000, step=100)\n",
    "            validation_split = trial.suggest_categorical(\"validation_split\", [0.2, 0.3, 0.4])\n",
    "            use_lr_scheduler = trial.suggest_categorical(\"use_lr_scheduler\", [True, False])\n",
    "            lr_scheduler_factor = trial.suggest_categorical(\"lr_scheduler_factor\", [0.1, 0.2])\n",
    "            fit_patience = 200\n",
    "            lr_scheduler_patience = trial.suggest_categorical(\"lr_scheduler_patience\", [int(fit_patience/2), int(fit_patience/3), int(fit_patience/4),])\n",
    "            use_batch_norm = trial.suggest_categorical(\"use_batch_norm\", [True, False])\n",
    "            # 初始化模型\n",
    "            model = HybridVAEMultiTaskSklearn(input_dim=X.shape[1],\n",
    "                                            task_count=y.shape[1],\n",
    "                                            vae_hidden_dim=vae_hidden_dim,\n",
    "                                            vae_depth=vae_depth,\n",
    "                                            vae_dropout_rate=vae_dropout_rate,\n",
    "                                            latent_dim=latent_dim,\n",
    "                                            predictor_hidden_dim=predictor_hidden_dim,\n",
    "                                            predictor_depth=predictor_depth,\n",
    "                                            predictor_dropout_rate=predictor_dropout_rate,\n",
    "                                            vae_lr=vae_lr,\n",
    "                                            vae_weight_decay=vae_weight_decay,\n",
    "                                            multitask_lr=multitask_lr,\n",
    "                                            multitask_weight_decay=multitask_weight_decay,\n",
    "                                            alphas=None,\n",
    "                                            beta=beta,\n",
    "                                            gamma_task=gamma_task,\n",
    "                                            batch_size=batch_size,\n",
    "                                            validation_split=validation_split,\n",
    "                                            use_lr_scheduler=use_lr_scheduler,\n",
    "                                            lr_scheduler_factor=lr_scheduler_factor,\n",
    "                                            lr_scheduler_patience=lr_scheduler_patience,\n",
    "                                            use_batch_norm=use_batch_norm,\n",
    "                                            )\n",
    "            # 实现交叉验证\n",
    "            kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=19960816)\n",
    "            aucs_1 = []\n",
    "            aucs_2 = []\n",
    "            recon_losses = []\n",
    "            vae_losses = []\n",
    "\n",
    "            for i, (train_index, val_index) in enumerate(kf.split(X, y.iloc[:,0])): # stratified by primary outcome\n",
    "                # 划分训练集和验证集\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "                \n",
    "                # 训练模型\n",
    "                model.fit(X_train, y_train,\n",
    "                            epochs=2000, \n",
    "                            early_stopping=True, \n",
    "                            patience=fit_patience,\n",
    "                            verbose=0, \n",
    "                            plot_path=None,\n",
    "                            save_weights_path=None)\n",
    "                \n",
    "                # 验证模型并记录分数\n",
    "                auc1, auc2 = model.score(X_val, y_val)  # 默认AUC\n",
    "                total_loss, recon_loss, kl_loss, task_loss = model.eval_loss(X, y)\n",
    "                vae_loss = recon_loss + model.beta * kl_loss\n",
    "\n",
    "                aucs_1.append(auc1)\n",
    "                aucs_2.append(auc2)\n",
    "                recon_losses.append(recon_loss)\n",
    "                vae_losses.append(vae_loss)\n",
    "\n",
    "            # 返回平均交叉验证分数（负均方误差）\n",
    "            return np.mean(aucs_1), np.mean(aucs_2), np.mean(vae_losses), np.mean(recon_losses)\n",
    "        except Exception as e:\n",
    "            print(f\"Trial failed with error: {e}\")\n",
    "            return -np.inf, -np.inf, np.inf, np.inf\n",
    "\n",
    "\n",
    "    # 日志功能：设置 Optuna 的日志级别\n",
    "    # optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "    # 实时打印当前最佳结果\n",
    "    def trial_callback(study, trial):\n",
    "        if IN_NOTEBOOK:\n",
    "            clear_output(wait=True)  # 清除之前的输出\n",
    "            df_trials = study.trials_dataframe()  # 获取当前的试验数据\n",
    "            display(df_trials)  # 动态显示最新的 dataframe\n",
    "\n",
    "            # 多目标优化时 打印 Pareto 前沿解\n",
    "            if len(study.directions) > 1:\n",
    "                pareto_front = study.best_trials\n",
    "                print(f\"Number of Pareto optimal solutions: {len(pareto_front)}\")\n",
    "                for i, trial in enumerate(pareto_front):\n",
    "                    print(f\"Pareto solution {i}: Values {trial.values}, Params {trial.params}\")\n",
    "            else:\n",
    "                print(f\"Current best value: {study.best_value}\")\n",
    "                print(f\"Current best parameters: {study.best_params}\")\n",
    "                print(f\"Current best trial: {study.best_trials}\")\n",
    "        else:\n",
    "            # 多目标优化时 打印首选 Pareto 前沿解的结果和参数\n",
    "            if len(study.directions) > 1:\n",
    "                pareto_front = study.best_trials\n",
    "                best_trial = pareto_front[0]\n",
    "                print(f\"Trial {trial.number}/{N_TRIAL} finished with value: {trial.values} and parameters: {trial.params} | crrent best value: {best_trial.values} and parameters: {best_trial.params} | Number of Pareto optimal solutions: {len(pareto_front)}\")\n",
    "            else:\n",
    "                print(f\"Trial {trial.number}/{N_TRIAL} finished with value: {trial.value} and parameters: {trial.params} | crrent best value: {study.best_value} and parameters: {study.best_params}\")\n",
    "\n",
    "\n",
    "    # 使用 Optuna 优化\n",
    "    study = optuna.create_study(directions=[\"maximize\", \"maximize\", \"minimize\", 'minimize'])  # 或 \"minimize\"，取决于评分标准\n",
    "    study.optimize(objective, n_trials=N_TRIAL, callbacks=[trial_callback])\n",
    "\n",
    "    # 保存实验结果\n",
    "    with open(f\"{risk_hybrid_vae}/optuna_study.pkl\", \"wb\") as f:\n",
    "        print('调参结束，正在保存optuna调参试验结果')\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "    # 获取 Pareto 前沿解\n",
    "    pareto_front = study.best_trials\n",
    "    print(\"Pareto Front Solutions:\")\n",
    "    for trial in pareto_front:\n",
    "        print(f\"Trial {trial.number}: Values {trial.values}, Params {trial.params}\")\n",
    "\n",
    "    # 保存 Pareto 解到文件\n",
    "    pareto_data = [\n",
    "        {\"trial_number\": trial.number, \"values\": trial.values, \"params\": trial.params}\n",
    "        for trial in pareto_front\n",
    "    ]\n",
    "    with open(f\"{risk_hybrid_vae}/pareto_solutions.json\", \"w\") as f:\n",
    "        json.dump(pareto_data, f)\n",
    "\n",
    "\n",
    "    # 保存完整调参历史为 xlsx 文件\n",
    "    df_trials = study.trials_dataframe()\n",
    "    df_trials.to_excel(f\"{risk_hybrid_vae}/tuning_history.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb058862-33cc-4901-b0cd-906bc9f7c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE=='tuning':\n",
    "    pass\n",
    "\n",
    "elif RUN_MODE=='reload':\n",
    "    with open(f\"{risk_hybrid_vae}/optuna_study.pkl\", \"rb\") as f:\n",
    "        print('正在加载指定optuna调参试验结果')\n",
    "        study = pickle.load(f)\n",
    "        \n",
    "# 使用一个 Pareto 最优解重新初始化模型\n",
    "pareto_front = study.best_trials\n",
    "best_trial = pareto_front[0] # 选择第一个 Pareto 解\n",
    "best_params = best_trial.params\n",
    "\n",
    "# 使用最佳参数重新初始化模型\n",
    "best_model = HybridVAEMultiTaskSklearn(input_dim=X.shape[1],\n",
    "                                        task_count=y.shape[1],\n",
    "                                        vae_hidden_dim=best_params[\"vae_hidden_dim\"],\n",
    "                                        vae_depth=best_params[\"vae_depth\"],\n",
    "                                        vae_dropout_rate=best_params[\"vae_dropout_rate\"],\n",
    "                                        latent_dim=best_params[\"latent_dim\"],\n",
    "                                        predictor_hidden_dim=best_params[\"predictor_hidden_dim\"],\n",
    "                                        predictor_depth=best_params[\"predictor_depth\"],\n",
    "                                        predictor_dropout_rate=best_params[\"predictor_dropout_rate\"],\n",
    "                                        vae_lr=best_params[\"vae_lr\"],\n",
    "                                        vae_weight_decay=best_params[\"vae_weight_decay\"],\n",
    "                                        multitask_lr=best_params[\"multitask_lr\"],\n",
    "                                        multitask_weight_decay=best_params[\"multitask_weight_decay\"],\n",
    "                                        alphas=None,\n",
    "                                        beta=best_params[\"beta\"],\n",
    "                                        gamma_task=best_params[\"gamma_task\"],\n",
    "                                        batch_size=best_params[\"batch_size\"],\n",
    "                                        validation_split=best_params[\"validation_split\"],\n",
    "                                        )\n",
    "\n",
    "# 训练最佳模型\n",
    "print('使用最佳参数在全集上训练模型')\n",
    "best_model.fit(X, y,\n",
    "                epochs=2000, \n",
    "                early_stopping=True, \n",
    "                patience=200,\n",
    "                verbose=2, \n",
    "                animate_monitor=True,\n",
    "                plot_path=risk_hybrid_vae,\n",
    "                save_weights_path=risk_hybrid_vae)\n",
    "\n",
    "print(f'最终AUC: {best_model.score(X, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e43c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制不同的图表\n",
    "target_args_1 = dict(target = lambda t: -t.values[0], target_name=\"AUC-primary\")\n",
    "target_args_2 = dict(target = lambda t: -t.values[1], target_name=\"AUC-secondary\")\n",
    "target_args_3 = dict(target = lambda t: -t.values[2], target_name=\"VAE loss\")\n",
    "target_args_4 = dict(target = lambda t: -t.values[3], target_name=\"Reconstruction MSE\")\n",
    "targets_args = dict(targets = lambda t: [t.values[0], -t.values[2]], target_names=[\"AUC\", \"VAE loss\"])\n",
    "\n",
    "# 并行坐标图\n",
    "parallel_coordinate_fig = plot_parallel_coordinate(study, **target_args_1)\n",
    "parallel_coordinate_fig.update_layout(width=800, height=600)\n",
    "parallel_coordinate_fig.show() if IN_NOTEBOOK else None\n",
    "parallel_coordinate_fig.write_image(f\"{risk_hybrid_vae}/parallel_coordinate_fig.svg\", format='svg', scale=2, width=700, height=500) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 参数重要性图\n",
    "param_importance_fig = plot_param_importances(study, **target_args_1)\n",
    "param_importance_fig.update_layout(width=800, height=600)\n",
    "param_importance_fig.show() if IN_NOTEBOOK else None\n",
    "param_importance_fig.write_image(f\"{risk_hybrid_vae}/param_importance_fig.svg\", format='svg', scale=2, width=700, height=500) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 平行曲面图\n",
    "contour_fig = plot_contour(study, **target_args_1)\n",
    "contour_fig.update_layout(width=1200, height=1200)\n",
    "contour_fig.show() if IN_NOTEBOOK else None\n",
    "contour_fig.write_image(f\"{risk_hybrid_vae}/contour_fig.svg\", format='svg', scale=2, width=1200, height=1200) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 超参数分布图\n",
    "slice_fig = plot_slice(study, **target_args_1)\n",
    "slice_fig.show() if IN_NOTEBOOK else None\n",
    "slice_fig.write_image(f\"{risk_hybrid_vae}/slice_fig.svg\", format='svg', scale=2, width=2500, height=400) if not IN_NOTEBOOK else None\n",
    "\n",
    "# 优化历史图\n",
    "optimization_history_fig = plot_optimization_history(study, **target_args_1)\n",
    "optimization_history_fig.update_layout(width=700, height=500)\n",
    "optimization_history_fig.show() if IN_NOTEBOOK else None\n",
    "optimization_history_fig.write_image(f\"{risk_hybrid_vae}/optimization_history_fig.svg\", format='svg', scale=2, width=700, height=500) if not IN_NOTEBOOK else None\n",
    "\n",
    "# Pareto 前沿图（仅适用于多目标优化）\n",
    "if len(study.directions) > 1:\n",
    "    pareto_fig = plot_pareto_front(study, **targets_args)\n",
    "    pareto_fig.update_layout(width=1200, height=800)\n",
    "    pareto_fig.show() if IN_NOTEBOOK else None\n",
    "    pareto_fig.write_image(f\"{risk_hybrid_vae}/pareto_fig.svg\", format='svg', scale=2, width=1200, height=1200) if not IN_NOTEBOOK else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d27b1",
   "metadata": {},
   "source": [
    "# Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HybridVAEMultiTaskSklearn(input_dim=X.shape[1],\n",
    "#                                 task_count=y.shape[1],\n",
    "#                                 vae_hidden_dim=50,\n",
    "#                                 vae_depth=1,\n",
    "#                                 vae_dropout_rate=0.3,\n",
    "#                                 latent_dim=10,\n",
    "#                                 predictor_hidden_dim=20,\n",
    "#                                 predictor_depth=1,\n",
    "#                                 predictor_dropout_rate=0.3,\n",
    "#                                 vae_lr=0.001,\n",
    "#                                 vae_weight_decay=0.001,\n",
    "#                                 multitask_lr=0.001,\n",
    "#                                 multitask_weight_decay=0.001,\n",
    "#                                 alphas=None,\n",
    "#                                 beta=1.0,\n",
    "#                                 gamma_task=1.0,\n",
    "#                                 batch_size=200,\n",
    "#                                 validation_split=0.3,\n",
    "#                                 )\n",
    "\n",
    "# model = model.fit(X,y, verbose=2, early_stopping=True)\n",
    "# print(model.score(X,y))\n",
    "# total_loss, recon_loss, kl_loss, task_loss = model.eval_loss(X, y)\n",
    "# print(total_loss, recon_loss, kl_loss, task_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
